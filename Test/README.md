# The steps for reproducing testing

## Trained models
We first provide 33 trained models to facilitate reproducing. The 33 trained models are obtained according to the provided training codes in training parts by ourselves. The 33 trained models are stored in 11 folders seperately, and you can download them from [**here**](https://drive.google.com/drive/folders/1xVIJdwCDbxVTjmlzo7YXUmlc8JwTUUgA?usp=sharing).

There is a one-to-one relation between the name of training datasets and the name of folders that stores trained models. 

| Training datasets  | Folders storing models |
| ------------- | ------------- |
| isc_100k_256_big_bw  | V5_baseline_BW  |
| isc_100k_256_big | V5_baseline_CC  |
| isc_100k_256_big_blur_bw  | V5_blur_BW  |
| isc_100k_256_big_blur  | V5_blur_CC  |
| isc_100k_256_big_color_p4_bw  | V5_color_BW  |
| isc_100k_256_big_color_p4 | V5_color_CC  |
| isc_100k_256_big_dark | V5_dark_CC  |
| isc_100k_256_big_ff_bw | V5_face_BW  |
| isc_100k_256_big_ff| V5_face_CC  |
| isc_100k_256_big_opa | V5_opa_CC  |
| isc_100k_256_big_u | V5_u_CC  |

These 11 folders are also given in the test part. You should download the trained models by yourselves and store them into the according folders seperately.

## Generate datasets
We augment query and reference datasets to match locally. The codes for augmentation are given in ```augmentation``` folder. By the way, to run theses augmentations, it is assumed that all the original query images and generated images are saved in ```/dev/shm```.

### Query
For query, we design four augmentations, i.e. rotating, center cropping, selective search, and detection.

Please Remember the original image!

Rotating: We rotate an image 90, 180, and 270 degrees to generate three images.

```
python rotate.py
```

Center cropping: We use center cropping to generate 5 images, and the illustrations are as follows.

![The first center cropping](https://github.com/WangWenhao0716/ISC-Track1-Submission/blob/main/Test/aug_1.pdf)

![The second center cropping](https://github.com/WangWenhao0716/ISC-Track1-Submission/blob/main/Test/aug_2.pdf)

```
python center.py
```

Selective search: We perform selective search and NMS to find the interested parts of an image. Note that selective search is very time-consuming, therefore using multi-cores CPUs manually is highly recommended (Sorry for not developing automatically programmes). 

```
python selective_search_nms.py
```

Detection: We use Yolo-V5 to detect overlay images. The related training and test codes and readme are given in ```augmentation/query/yolov5``` Folder.

Finally, after all the images are generated, you should generate file list ```dev_queries_exp_VD``` by running 
```
python generate_file_list_q.py
```


For example, if the name of the original image is ```Q00000.jpg```, then we will have the following names after the augmentations: 

Original: ```Q00000_0.jpg```

Rotating: ```Q00000_1.jpg~Q00000_3.jpg```

Center cropping: ```Q00000_4.jpg~Q00000_8.jpg```

Selective search: ```Q00000_10.jpg~Q00000_99.jpg``` (The number of images generated by selective search is less than 90.)

Detection: ```Q00000_100.jpg~...```


### Reference
For reference, we only design one augmentation, i.e. dividing. The illustrations are as follows.

![The first dividing](https://github.com/WangWenhao0716/ISC-Track1-Submission/blob/main/Test/aug_3.pdf)

![The second dividing](https://github.com/WangWenhao0716/ISC-Track1-Submission/blob/main/Test/aug_4.pdf)


Note that, though we only have one augmentation, each image can generate 1 + (4 + 1) + (9 + 4) = 19 images, and total 19x1,000,000 = 19,000,000 images are generated . Therefore, please prepare enough storage to store the generated images and corresponding features. Please do NOT store low quality images, which may reduce the performance.

```
python dividing.py
```

Finally, after all the images are generated, you should generate file list ```dev_reference_exp``` by running 
```
python generate_file_list_r.py
```

## Test
Until now, we have 3x11 = 33 trained models, augmented query images, and augmented reference images. The test processing can be divided into two parts: Using augmented query images with original reference images (AQ+OR), and using original query images with augmented reference image (OQ+AR). For AQ+OR, we use three models, and for OQ+AR, we only use three models. All of the related files are stored in ```final``` folder.

### AQ + OR
All the 33 trained models are used to test. We take V5_baseline_CC (isc_100k_256_big) for instance, the folder has three trained models, i.e. baseline_cc_50.pth.tar, baseline_cc_152.pth.tar, baseline_cc_ibn.pth.tar. Other 10 folders follow the similar pipelines.

We can enter into the folder by ```cd final/V5_baseline_CC```. 

It is assumed that training images are saved in ```/dev/shm/training_images```, original reference images are saved in ```/dev/shm/reference_images```, augmented query images are saved in ```/dev/shm/query_images_exp_VD```

You should gain PCA file and features of reference images by:
```
bash extract_reference_152.sh
bash extract_reference_50.sh
bash extract_reference_ibn.sh
```
There is no specified squence for running the three scripts. However, you should accomplished the three files before running the followings.
Then, extract features of training and augmented query images by:
```
bash extract_training_152.sh
bash extract_training_50.sh
bash extract_training_ibn.sh
bash extract_query_152_VD.sh
bash extract_query_50_VD.sh
bash extract_query_ibn_VD.sh
```

After all the features are extracted, you should run 
```
bash score_normalization_152.sh
bash score_normalization_50.sh
bash score_normalization_ibn.sh
```
Note that the number of augmented query images is unknown now, we estimate this number, and assume the features of augmented query images are stored in ```query_{0..28}_byol_VD_50k.hdf5```. However, the number of 28 may be bigger or smaller.

Finally, we will get 
```
V5_baseline_CC/152/predictions_dev_queries_50k_normalized_exp_VD.csv
V5_baseline_CC/50/predictions_dev_queries_50k_normalized_exp_VD.csv
V5_baseline_CC/ibn/predictions_dev_queries_50k_normalized_exp_VD.csv
```

For all other 10 folders, please perform the same action to get the final ```csv``` files, and all the ```.sh``` files for each folder have been prepared for you.

### OQ + AR





## Ensemble methods
